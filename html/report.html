<html>
<head>
<title>CS 5421 Report</title>
<link href='http://fonts.googleapis.com/css?family=Nunito:300|Crimson+Text|Droid+Sans+Mono' rel='stylesheet' type='text/css'>
<link rel="stylesheet" title="Default" href="styles/github.css">
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>  

<link rel="stylesheet" href="highlighting/styles/default.css">
<script src="highlighting/highlight.pack.js"></script>

<style type="text/css">
body {
	margin: 0px;
	width: 100%;
	font-family: 'Crimson Text', serif;
	font-size: 20px;
	background: #fcfcfc;
}
h1 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 28px;
	margin: 25px 0px 0px 0px;
	text-transform: lowercase;

}

h2 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 32px;
	margin: 15px 0px 35px 0px;
	color: #333;	
	word-spacing: 3px;
}

h3 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 26px;
	margin: 10px 0px 10px 0px;
	color: #333;
	word-spacing: 2px;
}
h4 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 22px;
	margin: 10px 0px 10px 0px;
	color: #333;
	word-spacing: 2px;
}

h5 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 18px;
	margin: 10px 0px 10px 0px;
	color: #111;
	word-spacing: 2px;
}

p, li {
	color: #444;
}

a {
	color: #DE3737;
}

.container {
	margin: 0px auto 0px auto;
	width: 1160px;
}

#header {
	background: #333;
	width: 100%;
}

#headersub {
	color: #ccc;
	width: 960px;
	margin: 0px auto 0px auto;
	padding: 20px 0px 20px 0px;
}

.chart {
	width: 480px;
}
.lol {
	font-size: 16px;
	color: #888;
	font-style: italic;
}
.sep {
	height: 1px;
	width: 100%;
	background: #999;
	margin: 20px 0px 20px 0px;
}
.footer{
	font-size: 16px;
}
.latex {
	width: 100%;
}

.latex img {
	display: block;
	margin: 0px auto 0px auto;
}

pre {
	font-family: 'Droid Sans Mono';
	font-size: 14px;
}

table td {
  text-align: center;
  vertical-align: middle;
}

table td img {
  text-align: center;
  vertical-align: middle;
}

#contents a {
}
</style>
<script type="text/javascript">
    hljs.initHighlightingOnLoad();
</script>
</head>
<body>
<div id="header" >
<div id="headersub">
<h1>Zhuofei Huang <span style="color: #DE3737">(20456695)</span></h1>
<h1>Jiaxiang Shang <span style="color: #DE3737">(20487589)</span></h1>
</div>
</div>
<div class="container">

<h2>CS 5421 / Project 2 / Face Detection with a Sliding Window</h2>


<p> 	Our core algorithm for this project is Hog feature extraction and SVM classifier. </p>

<ol>
<li>Load positive training crops and random negative examples.(We code)</li>
<li>Train Classifier.(We code)</li>
<li>Examine learned classifier.</li>
<li>Run detector on test set.(We code)</li>
<li>Evaluate and Visualize detections.</li>
</ol>

<p>Before we start our experiment, we need to firstly download folder "data/" from the course page and then put it into the same folder as "code/" and "html/".</p>

<div style="clear:both">
<h3>Loading examples</h3>

<p> 	We load all positive examples from "data/caltech_faces/Caltech_CropFaces" and randomly N negative ones from "data/train_non_face_scenes", where we choose N = 10000. Notice that higher value of N will work strictly better. After loading them, we should extract Hog features by calling function "vl_hog" from VLFeat lib. We provide part of example codes on processing positive examples in below. </p>

<pre><code>
%example code
features_pos = zeros(num_images, (feature_params.template_size / feature_params.hog_cell_size)^2 * 31);

for index = 1:num_images
	img_path = fullfile(train_path_pos, image_files(index).name);
	img = imread(img_path);
	hog = vl_hog(single(img), feature_params.hog_cell_size);
	features_pos(index, :) = hog(:)';    
end

</code></pre>

<p>For convenience of multi-experiments, we save two matrixs, features_pos and features_neg, into .mat files separately after the first loading. </p>

<h3>Train Classifier</h3>

<p> 	After obtaining positive and negative examples, we use vl_svmtrain on our training features to get a linear classifier. In vl_svmtrain function, there are 3 parameters: features, labels, lambda, where labels are vectors with -1 and 1 values, and lambda we provide is 0.0001. Maybe smaller lambda will work better. Similar to above, we save parameters w and b of svm classifier into .mat file separately after first loading. </p>

<h3>Run detector on test set</h3>

<p> 	Here we execute a multi-scale detection on each test image, which means that we use sliding-window scanning on certain image in each inner loop, while we resize the image into a smaller scale to repeat the scanning tasks in each outer loop until the final size has reached the template size of Hog detector. So here we have three important parameters: scale, step_size and conf_threshold. </p>

<ol>
<li>scale: resize rate on each outer loop of multi-scale, in our experiment we set as 0.9(such value will make detector slower but gets more accurate results)</li>
<li>step_size: step size of sliding window, in our experiment we set as 3.</li>
<li>conf_threshold: threshold of confidence for which we choose out as true box. We set as 0.9. </li>
</ol>

<p> 	After we choose out all confident boxes, we use non_max_supr_bbox actually get somewhat slow with thousands of initial detections. And finally we can get all of correct boxes. In the following tables we will show our results on data/extra_test_scenes directory and the precision-recall curve. </p>

<table border=1>
<tr>
<td>
<img src="detections_cs143_2011_class_easy.jpg.png" width="24%"/>
<img src="detections_cs143_2011_class_hard.jpg.png"  width="24%"/>
<img src="detections_cs143_2013_class_easy_01.jpg.png" width="24%"/>
<img src="detections_cs143_2013_class_easy_02.jpg.png" width="24%"/>
</td>
</tr>

<tr>
<td>
<img src="detections_cs143_2013_class_hard_01.jpg.png" width="24%"/>
<img src="detections_cs143_2013_class_hard_02.jpg.png"  width="24%"/>
<img src="detections_cs143_2013_class_hard_03.jpg.png" width="24%"/>
<img src="detections_faculty_roster.jpg.png" width="24%"/>
</td>
</tr>

</table>



<center>
<p>
Detection on data/extra_test_scenes, using confidence threshold is 1.2, step size 3, scale rate 0.9
<p>
<img src="average_precision.png" />
<p>
Final Precision-Recall Curve on test_scene set
<p>

</center>